A WIP terminal- or command line-based script for mimicking the style and vocabulary of a given text.

Usage (will probably change):
$   cd ./grammar-pyml
$	python formatter.py ../data/lcw.txt
	(above automatically adds _processed to the output, use --writepath for different output)
$   python general_lm.py lcw_processed --config [one of "small", "medium", "large", or "custom"]
	(provide as an argument the basename of above writepath without the extension)
    ...
$   python generator.py lcw_processed
	OR
$	python generator.py lcw_processed -i [input .txt file to use as a seed] -n [number of words to generate]


Example Output:
1.	Character model trained on a 98kb file of Shakespeare with the medium config:
	DUKE:
	Alas, to Ratcliff? which you go with thee,
	For 'tis not desire to hold his spirits of your rudesty.
	CRESSIDA:
	Thus in the heart of heaven as let them too sad and since
	The most beggar that the bloody treasure of the goodly chamber.
	PISANIO:
	Well, who has not wonders of her spirits with his blood, the world could do his name,
	Thou shouldst be such me that have been above these trater break to make thee could you way
	That thou wilt be supposed bother Helen's sister's all speech back,
	And to the several strumpet from my service and the state
	Is not my single spirit of my body,
	That I have brought me what that day we must ready his sister.
	But on my friends are to bear my heart,
	When one is not yet ensue of excellent and fepher's,
	To see the pirtune of a love that they have strain'd
	I heard it by a man's reports,
	And with their head with my son, I would thou wilt be such my stand, and then she will prove it she
	were not these things in she should be such
	As maves a profes of death of all the sight
	Of with my single spirit of a man since they are all,
	Or they are poor to me,
	To peasy her with thee, and her dependent, for whose state
	Is not my head with him, and to be so friends,
	But think he was sovereign;
	Which thou not to discrack to thee that thou wast from thee.
	DUKE VINCENTIO:
	What is 'Tis more, my lord,
	He is my grace to die that then that have been a man was
	not here, and we should be spent;
	And with the looks of arms so friends and them,
	The bright buds of mine own.

2.	Character model trained on a 2.6mb file of H.P. Lovecraft's collected works with the current custom config:
	They were the searchers as they call it out of the stone and the stars - the strange statues on the stairs and body of stone and the stars and the stars of the stars and the stars of the stars. It was not so much that I was a strange and archaic continent whose strange colours were so strangely considerable to the strange desert of New York to the Street. The strange designs were all sort of strangers, and the strange staircase was so strangely confident that the strange state of the strange colour was a strange and unconscious exploring of the strange colour. The strange colour was a strange and almost fantastic strain of stranger, and the strange staircase was so strangely confident to the strange specimen - the strange designs and of the strange deserted man of the strange colour.

3. Word model trained on the same data with the same config:
	whereupon my old man was born , and the doctor had not been a man of a kind of delirium .
	 The doctor had been a very old man , and had been a poet , a privateersman of the plumber that had been a nightmare-spawning wand .
	 Charlemagne in balladry , Ibidus retired , and the doctor administered his father 's face .
	 He was a bachelor , a person , a person , a person , a person , a person , a person , a person , a person , a person , a somewhat remarkable and very picturesque , and a contemptible caricature .

4. Trained the same way, output supplemented with slightly random output choice;
	When I... moon was gibbous , and the moon shone down in the moonlight .
	 And when the moon was , the tumult of the moon were very great , and the whole thing was very great .
	 The next day , however , was a great barn-door ; and the next day descried the semi-vagabond figure and the curious , semi-visible bulk of the drums , and the gaily sinister flowers and paraphernalia sang that the cliff 's rim was not a single one .
	 The place was very low , and the whole thing was very great .
	 The captain had been very great , and the watchers had been resorted to the custom of a kind of delirium ; and the prospect was a kind to be a collector of a very old man .
	 The old man , who was born , had been a very peculiar cast , and the other chiefs of the furry thing had been found in the dark .


Eventual flow (original idea, may also be subject to change):
    - Create "general" language model using ptb set or similar, with concatenated collected works of the author being mimicked
    - Starting with trained master "general" model, train again exclusively on collected works of author w/high learning rate and potentially momentum-based descent function, idea being to jump from the minimum the model will presumably start out in to one closer to the author's voice
    - Generate sentences from "seed" sentence either typed by user or chosen at random from collected worksK

Huge thanks to adventuresinML for:
    https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/reader.py
and the TensorFlow tutorial it's adapted from:
    https://www.tensorflow.org/tutorials/sequences/recurrent
for the initial push in figuring this out.